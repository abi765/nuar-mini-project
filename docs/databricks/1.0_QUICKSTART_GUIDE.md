# ðŸš€ Databricks Quick Start Guide

## Step-by-Step Deployment

### 1. Push to GitHub

```bash
git add .
git commit -m "feat: Add Databricks deployment files"
git push origin main
```

### 2. Set Up Databricks Repos

1. Log into Databricks workspace
2. Click "Repos" in sidebar
3. Click "Add Repo"
4. Enter your GitHub repository URL
5. Click "Create Repo"

### 3. Configure Secrets

```bash
# Using Databricks CLI
databricks secrets create-scope --scope nuar_secrets
databricks secrets put --scope nuar_secrets --key openweather_api_key
```

### 4. Create Cluster

- Go to "Compute" â†’ "Create Cluster"
- Name: `nuar-cluster`
- Runtime: 14.3 LTS
- Node: Single Node
- Install libraries: `pyarrow geopandas pyproj shapely scipy`

### 5. Run Setup

1. Open `databricks_notebooks/setup_delta_tables.sql`
2. Run all cells to create catalog and tables
3. Open `databricks_notebooks/tests/smoke_test.py`
4. Run smoke test to validate setup

### 6. Run Bronze Layer

1. Update paths in notebooks (replace `YOUR_EMAIL`)
2. Run bronze layer notebooks in order:
   - `01_infrastructure.py`
   - `02_crime.py`
   - `03_weather.py`
   - `04_postcodes.py`

### 7. Verify Data

```sql
SELECT * FROM nuar_catalog.bronze.infrastructure LIMIT 10;
```

## Troubleshooting

- **Import errors**: Update `sys.path.append()` with your Repos path
- **Secret errors**: Create secret scope in Databricks UI
- **API timeouts**: Normal for large queries, wait and retry

## Next Steps

- Set up Workflows for automation
- Create Silver layer transformations
- Build Gold layer analytics
- Create dashboards

**Need help?** See [DATABRICKS_MIGRATION.md](../docs/DATABRICKS_MIGRATION.md)
